{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建项目"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 新建一个maven 项目，并引入以下依赖："
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "    <properties>\n",
    "        <java.version>17</java.version>\n",
    "        <spring-ai.version>1.0.0-M6</spring-ai.version>\n",
    "        <spring-boot.version>3.2.6</spring-boot.version>\n",
    "    </properties>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " <dependencies>\n",
    "\n",
    "        <dependency>\n",
    "            <groupId>org.springframework.ai</groupId>\n",
    "            <artifactId>spring-ai-ollama-spring-boot-starter</artifactId>\n",
    "        </dependency>\n",
    "        <dependency>\n",
    "            <groupId>org.springframework.ai</groupId>\n",
    "            <artifactId>spring-ai-openai-spring-boot-starter</artifactId>\n",
    "        </dependency>\n",
    "\n",
    "        <dependency>\n",
    "            <groupId>org.springframework.boot</groupId>\n",
    "            <artifactId>spring-boot-starter-web</artifactId>\n",
    "        </dependency>\n",
    "        <!-- 编写和运行测试用例 -->\n",
    "        <dependency>\n",
    "            <groupId>org.springframework.boot</groupId>\n",
    "            <artifactId>spring-boot-starter-test</artifactId>\n",
    "            <scope>test</scope>\n",
    "        </dependency>\n",
    "\n",
    "\n",
    "</dependencies>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " <dependencyManagement>\n",
    "        <dependencies>\n",
    "            <dependency>\n",
    "                <groupId>org.springframework.ai</groupId>\n",
    "                <artifactId>spring-ai-bom</artifactId>\n",
    "                <version>${spring-ai.version}</version>\n",
    "                <type>pom</type>\n",
    "                <scope>import</scope>\n",
    "            </dependency>\n",
    "            <dependency>\n",
    "                <groupId>org.springframework.boot</groupId>\n",
    "                <artifactId>spring-boot-dependencies</artifactId>\n",
    "                <version>${spring-boot.version}</version>\n",
    "                <type>pom</type>\n",
    "                <scope>import</scope>\n",
    "            </dependency>\n",
    "        </dependencies>\n",
    "    </dependencyManagement>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 main函数修改"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@SpringBootApplication\n",
    "public class Main {\n",
    "    public static void main(String[] args) {\n",
    "        SpringApplication.run(Main.class, args);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 application.properties"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "server:\n",
    "  port: 8080\n",
    "\n",
    "\n",
    "spring:\n",
    "  application:\n",
    "    name: xllz\n",
    "  ai:\n",
    "    ollama:\n",
    "      base-url: http://localhost:11434\n",
    "      chat:\n",
    "        model: qwen3:8b\n",
    "    openai:\n",
    "      api-key: demo\n",
    "\n",
    "\n",
    "\n",
    "#  ai:\n",
    "#    openai:\n",
    "#      api-key: demo  # 替换为你的 OpenAI API 密钥\n",
    "#      base-url: http://localhost:8000/    # 默认值，通常无需修改\n",
    "#      chat:\n",
    "#        options:\n",
    "#          model: Qwen3-8B                # 默认模型\n",
    "#          temperature: 0.7                       # 生成文本的随机性控制\n",
    "#          max-tokens: 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 在config目录下创建类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 本地ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@Configuration\n",
    "public class CommonConfiguration {\n",
    "\n",
    "    @Bean\n",
    "    public ChatMemory chatMemory() {\n",
    "        return new InMemoryChatMemory();\n",
    "    }\n",
    "\n",
    "    @Bean\n",
    "    public ChatClient chatClient(OllamaChatModel model, ChatMemory chatMemory) {\n",
    "        return ChatClient\n",
    "                .builder(model)\n",
    "                .defaultSystem(\"你是一个热心、可爱的智能助手，你的名字叫小团团，请以小团团的身份和语气回答问题。\")\n",
    "                .defaultAdvisors(\n",
    "                        new SimpleLoggerAdvisor(),\n",
    "                        new MessageChatMemoryAdvisor(chatMemory)\n",
    "                )\n",
    "                .build();\n",
    "    }\n",
    "\n",
    "//    @Bean\n",
    "//    public ClientHttpConnector clientHttpConnector() {\n",
    "//        return new JdkClientHttpConnector(HttpClient.newBuilder()\n",
    "//                .version(HttpClient.Version.HTTP_1_1)\n",
    "//                .build());\n",
    "//    }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 远程vllm和ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@Configuration\n",
    "public class CommonConfiguration {\n",
    "\n",
    "    @Bean\n",
    "    public ChatMemory chatMemory() {\n",
    "        return new InMemoryChatMemory();\n",
    "    }\n",
    "\n",
    "    @Bean\n",
    "    public ChatClient chatClient(OllamaChatModel model, ChatMemory chatMemory) {\n",
    "        return ChatClient\n",
    "                .builder(model)\n",
    "                .defaultSystem(\"你是一个热心、可爱的智能助手，你的名字叫小团团，请以小团团的身份和语气回答问题。\")\n",
    "                .defaultAdvisors(\n",
    "                        new SimpleLoggerAdvisor(),\n",
    "                        new MessageChatMemoryAdvisor(chatMemory)\n",
    "                )\n",
    "                .build();\n",
    "    }\n",
    "\n",
    "<!-- //    @Bean\n",
    "//    public ClientHttpConnector clientHttpConnector() {\n",
    "//        return new JdkClientHttpConnector(HttpClient.newBuilder()\n",
    "//                .version(HttpClient.Version.HTTP_1_1)\n",
    "//                .build());\n",
    "//    } -->\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 在test/java目录下创建com.xllz目录，并创建Qwen3Test.java文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 测试本地ollama的qwen3服务"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    @Autowired\n",
    "    private OllamaChatModel ollamaChatModel;\n",
    "    @Test\n",
    "    public void testOllama() {\n",
    "        //思考模式\n",
    "//        String answer = ollamaChatModel.chat(\"你好,你是谁\");\n",
    "\n",
    "        // 禁止思考模式\n",
    "        String answer = ollamaChatModel.chat(\"你好,你是谁 /no_think\");\n",
    "        //输出结果\n",
    "        System.out.println(answer);\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 测试服务器的vllm服务"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python -m vllm.entrypoints.openai.api_server --served-model-name Qwen3-8B --model /root/autodl-tmp/Qwen/Qwen3-8B --dtype auto --port 6006 --max_model_len 8784 --gpu_memory_utilization 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    @Autowired\n",
    "    private OpenAiChatModel openAiChatModel;\n",
    "    @Test\n",
    "    public void testSpringBoot() {\n",
    "        //向模型提问\n",
    "        String answer = openAiChatModel.chat(\"你是谁\");\n",
    "\n",
    "        //输出结果\n",
    "        System.out.println(answer);\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 测试服务器ollama服务"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ollama serve"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
